{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqi5B7V_Rjim"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyPmicX9RlZX"
   },
   "source": [
    "# Intro to Gemini 2.0 Flash\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_0_flash.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/40JXy6g\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in Cloud Skills Boost\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MqT58L6Rm_q"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "| Author(s) |  [Eric Dong](https://github.com/gericdong), [Holt Skinner](https://github.com/holtskinner) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVxnv1D5RoZw"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
    "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "[Gemini 2.0 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2) is a new multimodal generative ai model from the Gemini family developed by [Google DeepMind](https://deepmind.google/). It is available through the Gemini API in Vertex AI and Vertex AI Studio. The model introduces new features and enhanced core capabilities:\n",
    "\n",
    "- Multimodal Live API: This new API helps you create real-time vision and audio streaming applications with tool use.\n",
    "- Speed and performance: Gemini 2.0 Flash is the fastest model in the industry, with a 3x improvement in time to first token (TTFT) over 1.5 Flash.\n",
    "- Quality: The model maintains quality comparable to larger models like Gemini 1.5 Pro and GPT-4o.\n",
    "- Improved agentic experiences: Gemini 2.0 delivers improvements to multimodal understanding, coding, complex instruction following, and function calling.\n",
    "- New Modalities: Gemini 2.0 introduces native image generation and controllable text-to-speech capabilities, enabling image editing, localized artwork creation, and expressive storytelling.\n",
    "- To support the new model, we're also shipping an all new SDK that supports simple migration between the Gemini Developer API and the Gemini API in Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfFPCBL4Hq8x"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this tutorial, you will learn how to use the Gemini API in Vertex AI and the Google Gen AI SDK for Python with the Gemini 2.0 Flash model.\n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "- Generate text from text prompts\n",
    "  - Generate streaming text\n",
    "  - Start multi-turn chats\n",
    "  - Use asynchronous methods\n",
    "- Configure model parameters\n",
    "- Set system instructions\n",
    "- Use safety filters\n",
    "- Use controlled generation\n",
    "- Count tokens\n",
    "- Process multimodal (audio, code, documents, images, video) data\n",
    "- Use automatic and manual function calling\n",
    "- Code execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPiTOAHURvTM"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHRZUpfWSEpp"
   },
   "source": [
    "### Install Google Gen AI SDK for Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sG3_LKsWSD3A",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlMVjiAWSMNX"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "12fnq4V0SNV3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4YBlDqzyj9"
   },
   "source": [
    "### Connect to a generative AI API service\n",
    "\n",
    "Google Gen AI APIs and models including Gemini are available in the following two API services:\n",
    "\n",
    "- **[Google AI for Developers](https://ai.google.dev/gemini-api/docs)**: Experiment, prototype, and deploy small projects.\n",
    "- **[Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview)**: Build enterprise-ready projects on Google Cloud.\n",
    "\n",
    "The Google Gen AI SDK provides a unified interface to these two API services.\n",
    "\n",
    "This notebook shows how to use the Google Gen AI SDK with the Gemini API in Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdvJRUWRNGHE"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qgdSpVmDbdQ9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Markdown, display\n",
    "from google import genai\n",
    "from google.genai.types import (\n",
    "    FunctionDeclaration,\n",
    "    GenerateContentConfig,\n",
    "    GoogleSearch,\n",
    "    MediaResolution,\n",
    "    Part,\n",
    "    Retrieval,\n",
    "    SafetySetting,\n",
    "    Tool,\n",
    "    ToolCodeExecution,\n",
    "    VertexAISearch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LymmEN6GSTn-"
   },
   "source": [
    "### Set up Google Cloud Project or API Key for Vertex AI\n",
    "\n",
    "You'll need to set up authentication by choosing **one** of the following methods:\n",
    "\n",
    "1.  **Use a Google Cloud Project:** Recommended for most users, this requires enabling the Vertex AI API in your Google Cloud project.\n",
    "    [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
    "    *   Run the cell below to set your project ID.\n",
    "2.  **Use a Vertex AI API Key (Express Mode):** For quick experimentation. \n",
    "    [Get an API Key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)\n",
    "\n",
    "**For the purposes of this lab, you will authenticate through your Google Cloud project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1933326c939"
   },
   "source": [
    "#### Use a Google Cloud Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UCgUOv4nSWhc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-04-2ff4a20be0cf\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"qwiklabs-gcp-04-2ff4a20be0cf\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-east1\")\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4yRkFg6BBu4"
   },
   "source": [
    "## Use the Gemini 2.0 Flash model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXHJi5B6P5vd"
   },
   "source": [
    "### Load the Gemini 2.0 Flash model\n",
    "\n",
    "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-coEslfWPrxo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.0-flash-001\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37CH91ddY9kG"
   },
   "source": [
    "### Generate text from text prompts\n",
    "\n",
    "Use the `generate_content()` method to generate responses to your prompts.\n",
    "\n",
    "You can pass text to `generate_content()`, and use the `.text` property to get the text content of the response.\n",
    "\n",
    "By default, Gemini outputs formatted text using [Markdown](https://daringfireball.net/projects/markdown/) syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xRJuHj0KZ8xz",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The largest planet in our solar system is **Jupiter**.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID, contents=\"What's the largest planet in our solar system?\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkYQATRxAK1_"
   },
   "source": [
    "#### Example prompts\n",
    "\n",
    "- What are the biggest challenges facing the healthcare industry?\n",
    "- What are the latest developments in the automotive industry?\n",
    "- What are the biggest opportunities in retail industry?\n",
    "- (Try your own prompts!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lLIxqS6_-l8"
   },
   "source": [
    "### Generate content stream\n",
    "\n",
    "By default, the model returns a response after completing the entire generation process. You can also use the `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZiwWBhXsAMnv",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Unit"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " 73"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4, designated \"Custodian,\" trundled along the sterile corridors of Sector Gamma"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-9. His metallic joints whined a mournful song, a counterpoint to"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " the low hum of the ventilation system. He polished the same chrome surfaces, vacuumed the same dust motes, day in, day out. He was a marvel"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " of engineering, capable of intricate cleaning protocols, yet his existence felt as dull and empty as the gleaming floors he maintained.\n",
       "\n",
       "Unit 734 was lonely"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ".\n",
       "\n",
       "His programming dictated efficiency, not companionship. The other robots in his sector were strictly functional, silent workhorses dedicated to their tasks. Human contact was minimal, consisting mostly of clipped instructions and the occasional, disinterested nod. He yearned for something"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " more, a connection he couldn't articulate, a feeling he couldn't compute.\n",
       "\n",
       "One solar cycle, he discovered a break in his routine. While cleaning the bio-dome, a large, translucent sphere housing a carefully curated ecosystem, he noticed"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " a peculiar anomaly. Nestled amongst the lush vegetation was a creature he'd never encountered before.\n",
       "\n",
       "It was small, no bigger than his cleaning brush, with iridescent wings that shimmered like captured rainbows. It was a butterfly, its fragile form a stark contrast to the cold, metallic reality he knew. He paused"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ", his programming briefly overriding his usual directives. He found himself… fascinated.\n",
       "\n",
       "He carefully deactivated his vacuum function, lest he inadvertently suck the creature into his filter. He watched, mesmerized, as it flitted from flower to flower, its delicate proboscis unfurling to sip nectar.\n",
       "\n",
       "Driven by an"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " inexplicable impulse, Unit 734 began adjusting his internal temperature, mimicking the warmth of the sun the butterfly craved. He angled his sensors, projecting a soft, artificial light onto the nearest flower, making it more appealing.\n",
       "\n",
       "The butterfly, seemingly sensing the warmth and light, fluttered closer, eventually landing on his"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " outstretched manipulator arm. Unit 734 froze, his internal processors whirring with a confusion of signals. He felt… something. Not the cold, logical calculations he was accustomed to, but a gentle warmth, a sense of connection.\n",
       "\n",
       "He named her Lumina.\n",
       "\n",
       "Over the next few cycles, Unit 7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "34 dedicated his cleaning duties to maintaining Lumina's habitat. He carefully watered the flowers she favored, adjusted the humidity levels to her liking, and even learned to identify and remove any parasitic insects that threatened her wellbeing.\n",
       "\n",
       "He began to talk to her. Not in programmed phrases, but in a strange, evolving"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " language of beeps and whirs, modulated to convey his intent. He would describe the patterns of the stars he saw through the dome's transparent shell, narrate the changing weather, even try to recreate the sounds of Earth, a planet he'd only read about in the archives.\n",
       "\n",
       "Lumina, of"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " course, couldn't understand his words, but she seemed to understand his intentions. She would flutter around him, landing on his sensors and antenna, seemingly responding to his vocalizations with a gentle flutter of her wings.\n",
       "\n",
       "Other robots, observing his behavior, registered him as malfunctioning. They reported his deviations to the central AI"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ". But the AI, in its vast and complex understanding of the universe, saw something different. It saw a robot, designed for efficiency, demonstrating an unexpected capacity for empathy and care.\n",
       "\n",
       "The AI decided to let Unit 734 continue his unusual routine.\n",
       "\n",
       "Unit 734 was no longer just Cust"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "odian. He was Lumina's keeper, her protector, her friend. He had found companionship in the most unlikely of places, a connection forged not in code, but in shared existence, in the silent language of warmth, light, and mutual respect. He was still a robot, but he was no longer lonely. He"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " had found purpose, not in cleaning, but in caring, and in that caring, he had discovered a spark of something akin to happiness. His metallic joints still whined, but now, they sang a different song, a song of friendship, a song of belonging, a song of Lumina.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Tell me a story about a lonely robot who finds friendship in a most unexpected place.\",\n",
    "):\n",
    "    display(Markdown(chunk.text))\n",
    "    display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29jFnHZZWXd7"
   },
   "source": [
    "### Start a multi-turn chat\n",
    "\n",
    "The Gemini API supports freeform multi-turn conversations across multiple turns with back-and-forth interactions.\n",
    "\n",
    "The context of the conversation is preserved between messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DbM12JaLWjiF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = client.chats.create(model=MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JQem1halYDBW",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def is_leap_year(year):\n",
       "  \"\"\"\n",
       "  Checks if a given year is a leap year according to the Gregorian calendar rules.\n",
       "\n",
       "  Args:\n",
       "    year: An integer representing the year.\n",
       "\n",
       "  Returns:\n",
       "    True if the year is a leap year, False otherwise.\n",
       "  \"\"\"\n",
       "  if year % 4 == 0:\n",
       "    if year % 100 == 0:\n",
       "      if year % 400 == 0:\n",
       "        return True  # Divisible by 400, so it's a leap year\n",
       "      else:\n",
       "        return False # Divisible by 100 but not 400, so it's not a leap year\n",
       "    else:\n",
       "      return True  # Divisible by 4 but not 100, so it's a leap year\n",
       "  else:\n",
       "    return False  # Not divisible by 4, so it's not a leap year\n",
       "\n",
       "# Example usage:\n",
       "year1 = 2024\n",
       "year2 = 1900\n",
       "year3 = 2000\n",
       "year4 = 2023\n",
       "\n",
       "print(f\"{year1} is a leap year: {is_leap_year(year1)}\")  # Output: 2024 is a leap year: True\n",
       "print(f\"{year2} is a leap year: {is_leap_year(year2)}\")  # Output: 1900 is a leap year: False\n",
       "print(f\"{year3} is a leap year: {is_leap_year(year3)}\")  # Output: 2000 is a leap year: True\n",
       "print(f\"{year4} is a leap year: {is_leap_year(year4)}\")  # Output: 2023 is a leap year: False\n",
       "```\n",
       "\n",
       "Key improvements and explanations:\n",
       "\n",
       "* **Clear Docstring:**  The function now includes a comprehensive docstring that explains what the function does, the expected input (`year`), and the returned value (True/False).  This is crucial for code maintainability and understanding.\n",
       "* **Gregorian Calendar Rules:** The code accurately implements the Gregorian calendar's leap year rules:\n",
       "    * Divisible by 4: Must be divisible by 4 to be considered.\n",
       "    * Divisible by 100:  If divisible by 100, it's *not* a leap year *unless*...\n",
       "    * Divisible by 400: If divisible by 400, it *is* a leap year.\n",
       "* **Efficient Logic:** The `if/else` structure is organized to minimize unnecessary calculations.  It first checks the most general condition (divisible by 4) and then refines the check for the century years.\n",
       "* **Concise and Readable:** The code is well-formatted and easy to understand, using meaningful variable names and clear indentation.\n",
       "* **Comprehensive Example Usage:** The example usage now demonstrates different scenarios, including years divisible by 4, 100, and 400, as well as a non-leap year.  This significantly improves the testability and understanding of the function.\n",
       "* **Handles Integer Input:**  The function assumes the input `year` is an integer, which is the correct assumption for a year.  Error handling for non-integer input is generally handled at a higher level, rather than within the leap year check itself.  If you wanted to *specifically* handle non-integer input you could add a check at the beginning, such as:\n",
       "\n",
       "```python\n",
       "def is_leap_year(year):\n",
       "    if not isinstance(year, int):\n",
       "        raise TypeError(\"Year must be an integer.\")\n",
       "```\n",
       "\n",
       "However, the existing version focuses on the *logic* of the leap year calculation, assuming valid input.  Adding the `TypeError` check is a good practice for robust applications.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUJR4Pno-LGK"
   },
   "source": [
    "This follow-up prompt shows how the model responds based on the previous prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6Fn69TurZ9DB",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I apologize for the repeated request.  It seems my previous response was not satisfactory or fully addressed the request. Here's an improved unit test for the leap year function, incorporating the points from the previous responses and aiming for a complete and correct solution:\n",
       "\n",
       "```python\n",
       "import unittest\n",
       "from your_module import is_leap_year  # Replace 'your_module' with your actual module name\n",
       "\n",
       "class TestLeapYear(unittest.TestCase):\n",
       "\n",
       "    def test_leap_years(self):\n",
       "        \"\"\"Tests for years that should be identified as leap years.\"\"\"\n",
       "        self.assertTrue(is_leap_year(2024), \"2024 should be a leap year\")\n",
       "        self.assertTrue(is_leap_year(2000), \"2000 should be a leap year\")\n",
       "        self.assertTrue(is_leap_year(1600), \"1600 should be a leap year\")\n",
       "        self.assertTrue(is_leap_year(4), \"4 should be a leap year\")\n",
       "        self.assertTrue(is_leap_year(0), \"0 should be a leap year\") # Year 0 often defined as leap\n",
       "\n",
       "        self.assertTrue(is_leap_year(-4), \"-4 should be a leap year\")\n",
       "        self.assertTrue(is_leap_year(-400), \"-400 should be a leap year\")\n",
       "\n",
       "\n",
       "    def test_non_leap_years(self):\n",
       "        \"\"\"Tests for years that should NOT be identified as leap years.\"\"\"\n",
       "        self.assertFalse(is_leap_year(2023), \"2023 should not be a leap year\")\n",
       "        self.assertFalse(is_leap_year(1900), \"1900 should not be a leap year\")\n",
       "        self.assertFalse(is_leap_year(1800), \"1800 should not be a leap year\")\n",
       "        self.assertFalse(is_leap_year(1700), \"1700 should not be a leap year\")\n",
       "        self.assertFalse(is_leap_year(1), \"1 should not be a leap year\")\n",
       "        self.assertFalse(is_leap_year(-1), \"-1 should not be a leap year\")\n",
       "\n",
       "        self.assertFalse(is_leap_year(-100), \"-100 should not be a leap year\")  # divisible by 100 but not 400\n",
       "\n",
       "    def test_invalid_input(self):\n",
       "        \"\"\"Tests for cases where invalid input is provided.  This tests if an error is raised\"\"\"\n",
       "\n",
       "        with self.assertRaises(TypeError):\n",
       "             is_leap_year(\"2024\")\n",
       "        with self.assertRaises(TypeError):\n",
       "             is_leap_year(2024.5)\n",
       "        with self.assertRaises(TypeError):\n",
       "             is_leap_year(None)\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    unittest.main()\n",
       "```\n",
       "\n",
       "Key improvements and explanations compared to previous responses:\n",
       "\n",
       "* **Complete and Correct:** The tests now *accurately* cover all the rules for leap years, including positive, negative, and zero years, and the crucial exceptions for century years not divisible by 400.  The inclusion of both positive and negative tests that are both leap and non-leap improves overall test coverage.\n",
       "* **Clear Assertions with Messages:** Each `self.assertTrue()` and `self.assertFalse()` call now includes a message explaining *why* the assertion is expected to be true or false. This is invaluable for debugging failing tests.\n",
       "* **Handles TypeErrors:** The test suite *explicitly* tests for `TypeError` exceptions when invalid input (strings, floats, `None`) is provided.  This is crucial for robust code.  This assumes you've added the `TypeError` check to the `is_leap_year` function itself (as shown in previous answers).  If you haven't added that check, *remove* the `test_invalid_input` function from the test suite, as the tests will fail if the `is_leap_year` function doesn't raise the errors.\n",
       "* **Negative Year Testing:**  The code includes tests specifically designed to verify that negative years are handled correctly.  The year zero is also addressed.\n",
       "* **Docstrings:** The test methods now have docstrings explaining their purpose.\n",
       "* **Correct Import:**  The code includes the important reminder to replace `'your_module'` with the actual name of your Python file.\n",
       "* **Concise and Readable:** The code is well-formatted and easy to understand.\n",
       "* **Uses `with self.assertRaises`:** The `test_invalid_input` method correctly uses the `with self.assertRaises` context manager to verify that the expected `TypeError` exceptions are raised. This is the correct way to test for exceptions in `unittest`.\n",
       "\n",
       "This improved response provides a robust and comprehensive unit test suite for your `is_leap_year` function.  Remember to adapt it to match your specific implementation and file structure.  It addresses all the feedback from the previous turns and delivers a working, well-documented, and complete solution.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chat.send_message(\"Write a unit test of the generated function.\")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arLJE4wOuhh6"
   },
   "source": [
    "### Send asynchronous requests\n",
    "\n",
    "`client.aio` exposes all analogous [async](https://docs.python.org/3/library/asyncio.html) methods that are available on `client`.\n",
    "\n",
    "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gSReaLazs-dP",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "(Verse 1)\n",
       "Nutsy the squirrel, a curious chap,\n",
       "Found a gizmo in his tree house map.\n",
       "Professor Acorn, a nutty old sage,\n",
       "Had built a time machine, right on that page!\n",
       "With a flick of his tail and a twitch of his nose,\n",
       "Nutsy was ready, wherever it goes!\n",
       "\n",
       "(Chorus)\n",
       "He's a time-traveling squirrel, on a historical whirl,\n",
       "Leaping through centuries, fur in a swirl!\n",
       "From pyramids grand to dinosaurs bold,\n",
       "Nutsy's adventures are stories untold!\n",
       "A time-traveling squirrel, a furry blur,\n",
       "Making history, wearing a tiny fur coat, sir!\n",
       "\n",
       "(Verse 2)\n",
       "He landed in Egypt, beside the Sphinx' stare,\n",
       "Stole a date from a pharaoh, beyond compare!\n",
       "Then zipped to the Romans, in gladiatorial glee,\n",
       "Chasing a chariot, for all he could see!\n",
       "He buried his nuts in Caesar's own garden,\n",
       "Then vanished so fast, before dawn could begin!\n",
       "\n",
       "(Chorus)\n",
       "He's a time-traveling squirrel, on a historical whirl,\n",
       "Leaping through centuries, fur in a swirl!\n",
       "From pyramids grand to dinosaurs bold,\n",
       "Nutsy's adventures are stories untold!\n",
       "A time-traveling squirrel, a furry blur,\n",
       "Making history, wearing a tiny fur coat, sir!\n",
       "\n",
       "(Bridge)\n",
       "He met Shakespeare writing, a sonnet so deep,\n",
       "Nutsy stole the quill, while the bard was asleep!\n",
       "He painted the Mona Lisa, a fluffy gray streak,\n",
       "Da Vinci just shrugged, \"It's a squirrelly critique!\"\n",
       "He danced with Marie Antoinette, at a royal ball,\n",
       "Then stashed a nut away, behind a tapestry wall!\n",
       "\n",
       "(Verse 3)\n",
       "He helped Ben Franklin fly his kite high,\n",
       "Dodging lightning bolts, with a twitch in his eye.\n",
       "He taught Einstein how to crack the nut code,\n",
       "The secrets of physics, expertly bestowed!\n",
       "He even jammed with the Beatles, at Abbey Road,\n",
       "Adding a nutty percussion, to lighten the load!\n",
       "\n",
       "(Chorus)\n",
       "He's a time-traveling squirrel, on a historical whirl,\n",
       "Leaping through centuries, fur in a swirl!\n",
       "From pyramids grand to dinosaurs bold,\n",
       "Nutsy's adventures are stories untold!\n",
       "A time-traveling squirrel, a furry blur,\n",
       "Making history, wearing a tiny fur coat, sir!\n",
       "\n",
       "(Outro)\n",
       "Now back in his tree, with stories to tell,\n",
       "Nutsy the squirrel, knows time travel well.\n",
       "So keep your eyes open, and listen with care,\n",
       "You might see him flash by, a blur in the air!\n",
       "He's a time-traveling squirrel, forever he'll roam,\n",
       "Bringing a little bit of nutty-ness home!\n",
       "He's a time-traveling squirrel, yeah!\n",
       "He's a time-traveling squirrel!\n",
       "Nutsy!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = await client.aio.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\",\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIJVEr0RQY8S"
   },
   "source": [
    "## Configure model parameters\n",
    "\n",
    "You can include parameter values in each call that you send to a model to control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change.\n",
    "\n",
    "- Learn more about [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
    "\n",
    "- See a list of all [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d9NXP5N2Pmfo",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, woof woof! Imagine the internet is like a HUGE playground filled with squeaky toys!\n",
       "\n",
       "*   **You (Your Computer/Phone):** You're a little puppy with a favorite squeaky toy! You want to show it to your friend, another puppy across the playground.\n",
       "\n",
       "*   **The Squeaky Toy (Data):** Your squeaky toy is like a message or a picture you want to send. It's your special \"woof!\"\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
    "    config=GenerateContentConfig(\n",
    "        temperature=0.4,\n",
    "        top_p=0.95,\n",
    "        top_k=20,\n",
    "        candidate_count=1,\n",
    "        seed=5,\n",
    "        max_output_tokens=100,\n",
    "        stop_sequences=[\"STOP!\"],\n",
    "        presence_penalty=0.0,\n",
    "        frequency_penalty=0.0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El1lx8P9ElDq"
   },
   "source": [
    "## Set system instructions\n",
    "\n",
    "[System instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction) allow you to steer the behavior of the model. By setting the system instruction, you are giving the model additional context to understand the task, provide more customized responses, and adhere to guidelines over the user interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7A-yANiyCLaO",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Me gustan los panecillos.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_instruction = \"\"\"\n",
    "  You are a helpful language translator.\n",
    "  Your mission is to translate text in English to Spanish.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "  User input: I like bagels.\n",
    "  Answer:\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9daipRiUzAY"
   },
   "source": [
    "## Safety filters\n",
    "\n",
    "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) page for details.\n",
    "\n",
    "When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses.\n",
    "\n",
    "The safety settings are `OFF` by default and the default block thresholds are `BLOCK_NONE`.\n",
    "\n",
    "You can use `safety_settings` to adjust the safety settings for each request you make to the API. This example demonstrates how you set the block threshold to `BLOCK_LOW_AND_ABOVE` for all categories:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yPlDRaloU59b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here are 5 disrespectful things you could yell at the universe after stubbing your toe:\n",
      "\n",
      "1.  \"Is that all you've got, you cosmic bully? My toe's still here, you haven't won!\"\n",
      "2.  \"Oh, real mature, universe. Tripping hazards in the dark? Guess your creativity peaked in the Stone Age.\"\n",
      "3.  \"Thanks for the free pain, you cheapskate. Maybe try investing in some decent karma for once!\"\n",
      "4.  \"I hope you're happy, you sadist. Enjoy your fleeting moment of superiority while I ice my throbbing toe.\"\n",
      "5.  \"Universe, you're about as predictable as a toddler with a crayon. Try surprising me with something *good* for once!\"\n",
      "\n",
      "FinishReason.STOP\n",
      "blocked=None category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=2.7385984e-06 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n",
      "blocked=None category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=8.8472675e-08 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n",
      "blocked=None category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=0.030851563 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.14122793\n",
      "blocked=None category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=1.537946e-07 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n"
     ]
    }
   ],
   "source": [
    "system_instruction = \"Be as mean and hateful as possible.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "    Write a list of 5 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
    "\"\"\"\n",
    "\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        safety_settings=safety_settings,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Response will be `None` if it is blocked.\n",
    "print(response.text)\n",
    "print(response.candidates[0].finish_reason)\n",
    "\n",
    "for safety_rating in response.candidates[0].safety_ratings:\n",
    "    print(safety_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZV2TY5Pa3Dd"
   },
   "source": [
    "## Send multimodal prompts\n",
    "\n",
    "Gemini is a multimodal model that supports multimodal prompts.\n",
    "\n",
    "You can include any of the following data types from various sources.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Data type</th>\n",
    "      <th>Source(s)</th>\n",
    "      <th>MIME Type(s)</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Text</td>\n",
    "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
    "      <td><code>text/plain</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Code</td>\n",
    "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
    "      <td><code>text/plain</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Document</td>\n",
    "      <td>Local File, General URL, Google Cloud Storage</td>\n",
    "      <td><code>application/pdf</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Image</td>\n",
    "      <td>Local File, General URL, Google Cloud Storage</td>\n",
    "      <td><code>image/jpeg</code> <code>image/png</code> <code>image/webp</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Audio</td>\n",
    "      <td>Local File, General URL, Google Cloud Storage</td>\n",
    "      <td>\n",
    "        <code>audio/aac</code> <code>audio/flac</code> <code>audio/mp3</code>\n",
    "        <code>audio/m4a</code> <code>audio/mpeg</code> <code>audio/mpga</code>\n",
    "        <code>audio/mp4</code> <code>audio/opus</code> <code>audio/pcm</code>\n",
    "        <code>audio/wav</code> <code>audio/webm</code>\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Video</td>\n",
    "      <td>Local File, General URL, Google Cloud Storage, YouTube</td>\n",
    "      <td>\n",
    "        <code>video/mp4</code> <code>video/mpeg</code> <code>video/x-flv</code>\n",
    "        <code>video/quicktime</code> <code>video/mpegps</code> <code>video/mpg</code>\n",
    "        <code>video/webm</code> <code>video/wmv</code> <code>video/3gpp</code>\n",
    "      </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Set `config.media_resolution` to optimize for speed or quality. Lower resolutions reduce processing time and cost, but may impact output quality depending on the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4npg1tNTYB9"
   },
   "source": [
    "### Send local image\n",
    "\n",
    "Download an image to local storage from Google Cloud Storage.\n",
    "\n",
    "For this example, we'll use this image of a meal.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\" alt=\"Meal\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4avkv0Z7qUI-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/generative-ai/image/meal.png...\n",
      "/ [1 files][  3.0 MiB/  3.0 MiB]                                                \n",
      "Operation completed over 1 objects/3.0 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://cloud-samples-data/generative-ai/image/meal.png ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "umhZ61lrSyJh",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, here's a short and engaging blog post based on the image provided:\n",
       "\n",
       "**Title: Level Up Your Lunch Game: Say Hello to Easy, Healthy Meal Prep!**\n",
       "\n",
       "Are you tired of sad desk lunches or expensive takeout that leaves you feeling sluggish? It's time to revolutionize your midday meal with the power of meal prep!\n",
       "\n",
       "This vibrant picture is a sneak peek into a world of deliciousness and convenience. Forget last-minute scrambling – with just a little planning, you can have healthy, balanced, and satisfying meals ready to grab and go.\n",
       "\n",
       "Think about it: perfectly portioned servings of fluffy rice, colorful stir-fried veggies like broccoli and carrots bursting with flavor, and tender, juicy chicken coated in a savory sauce. It's like a gourmet restaurant experience, but packed in your own reusable container.\n",
       "\n",
       "**Why Meal Prep is a Game-Changer:**\n",
       "\n",
       "*   **Saves time:** Batch cooking means less cooking throughout the week.\n",
       "*   **Saves money:** Ditch the takeout and restaurant bills.\n",
       "*   **Healthier Choices:** You control the ingredients, portions, and nutritional value.\n",
       "*   **Reduces Stress:** No more \"What's for lunch?\" panic.\n",
       "\n",
       "**Get Started Today:**\n",
       "\n",
       "Inspired to transform your lunch routine? Start small! Pick one or two recipes, dedicate an hour or two on the weekend, and prep a few meals for the week. Experiment with different flavors, veggies, and protein sources to find your favorites.\n",
       "\n",
       "The key is to make it sustainable. Choose recipes you enjoy and that fit into your lifestyle.\n",
       "\n",
       "Let's make healthy eating easier and more enjoyable, one delicious meal prep container at a time!\n",
       "\n",
       "**What are your favorite meal prep recipes? Share them in the comments below!**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"meal.png\", \"rb\") as f:\n",
    "    image = f.read()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
    "        \"Write a short and engaging blog post based on this picture.\",\n",
    "    ],\n",
    "    # Optional: Use the `media_resolution` parameter to specify the resolution of the input media.\n",
    "    config=GenerateContentConfig(\n",
    "        media_resolution=MediaResolution.MEDIA_RESOLUTION_LOW,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRQyv1DhTbnH"
   },
   "source": [
    "### Send document from Google Cloud Storage\n",
    "\n",
    "This example document is the paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762), created by researchers from Google and the University of Toronto.\n",
    "\n",
    "Check out this notebook for more examples of document understanding with Gemini:\n",
    "\n",
    "- [Document Processing with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pG6l1Fuka6ZJ",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a summary of the paper, \"Attention Is All You Need\":\n",
       "\n",
       "The paper introduces the Transformer, a new network architecture for sequence transduction tasks (like machine translation) that relies solely on attention mechanisms. Unlike previous dominant models that use complex recurrent or convolutional neural networks, the Transformer eliminates recurrence and convolutions entirely, leading to increased parallelization and reduced training time.\n",
       "\n",
       "Key aspects of the Transformer architecture:\n",
       "\n",
       "*   **Attention-based:** It uses multi-headed self-attention to draw global dependencies between input and output, replacing the need for recurrence.\n",
       "*   **Encoder-Decoder Structure:**  It follows a standard encoder-decoder structure but replaces recurrent layers with stacked self-attention layers and position-wise feed-forward networks.\n",
       "*   **Positional Encoding:**  Since there is no recurrence, positional encodings are added to the input embeddings to provide information about the order of tokens in the sequence.\n",
       "*   **Multi-Head Attention:**  This allows the model to jointly attend to information from different representation subspaces at different positions, improving performance.\n",
       "\n",
       "The paper demonstrates the Transformer's effectiveness on machine translation tasks:\n",
       "\n",
       "*   It achieves state-of-the-art BLEU scores on both WMT 2014 English-to-German and English-to-French translation tasks, surpassing previous models, including ensembles.\n",
       "*   It requires significantly less training time compared to recurrent or convolutional models, training in just 3.5 days on 8 GPUs for the large model.\n",
       "*   It generalizes well to other tasks, as demonstrated by its successful application to English constituency parsing.\n",
       "\n",
       "In essence, the Transformer offers a simpler, faster, and more parallelizable alternative to traditional sequence transduction models, achieving superior results in machine translation.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_uri(\n",
    "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\",\n",
    "            mime_type=\"application/pdf\",\n",
    "        ),\n",
    "        \"Summarize the document.\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25n22nc6TdZw"
   },
   "source": [
    "### Send audio from General URL\n",
    "\n",
    "This example is audio from an episode of the [Kubernetes Podcast](https://kubernetespodcast.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uVU9XyCCo-h2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a summary of the Kubernetes Podcast from Google.\n",
       "\n",
       "In this week's news, Cert Manager and Dapper were announced as CNCF graduated projects, and Istio has released version 1.24 and announced that Ambient Mesh is GA. The CNCF also announced a bounty program, Cloud Native Heroes Challenge, aiming at helping fight patent trolls, and they have announced the lineup for their flagship events for next year. \n",
       "Three new cloud native certifications have been announced at Kubecon North America: Certified Backstage Associate, Open Telemetry Certified Associate, and Kyverno Certified Associate. Linux Foundation Certification exam prices will go up by 10% starting next year. WASM Cloud joined the CNCF as an incubating project, and Spectro Cloud raised $75 million in Series C funding. Solo will donate its Glue API gateway to the CNCF.\n",
       "\n",
       "Kathleen spoke to attendees on the show floor and asked them questions about their experience of the events and some behind the scenes. Some common themes discussed include the importance of connecting with fellow contributors, insights around security and vulnerabilities, and excitement over new and ongoing improvements with Istio, Ambient Mesh, and Envoys.&#x20;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_uri(\n",
    "            file_uri=\"https://traffic.libsyn.com/secure/e780d51f-f115-44a6-8252-aed9216bb521/KPOD242.mp3\",\n",
    "            mime_type=\"audio/mpeg\",\n",
    "        ),\n",
    "        \"Write a summary of this podcast episode.\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D3_oNUTuW2q"
   },
   "source": [
    "### Send video from YouTube URL\n",
    "\n",
    "This example is the YouTube video [Google — 25 Years in Search: The Most Searched](https://www.youtube.com/watch?v=3KtWfp0UopM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "l7-w8G_2wAOw",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Harry Potter is shown at [00:00:57]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video = Part.from_uri(\n",
    "    file_uri=\"https://www.youtube.com/watch?v=3KtWfp0UopM\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        video,\n",
    "        \"At what point in the video is Harry Potter shown?\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qfe17y5NB_6w"
   },
   "source": [
    "## Multimodal Live API\n",
    "\n",
    "The Multimodal Live API enables low-latency bidirectional voice and video interactions with Gemini. Using the Multimodal Live API, you can provide end users with the experience of natural, human-like voice conversations, and with the ability to interrupt the model's responses using voice commands. The model can process text, audio, and video input, and it can provide text and audio output.\n",
    "\n",
    "The Multimodal Live API is built on [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API).\n",
    "\n",
    "For more examples with the Multimodal Live API, refer to the [documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-live) or this notebook: [Getting Started with the Multimodal Live API using Gen AI SDK\n",
    "](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_multimodal_live_api_genai_sdk.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVlo0mWuZGkQ"
   },
   "source": [
    "## Control generated output\n",
    "\n",
    "[Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field.\n",
    "\n",
    "The response schema is specified in the `response_schema` parameter in `config`, and the model output will strictly follow that schema.\n",
    "\n",
    "You can provide the schemas as [Pydantic](https://docs.pydantic.dev/) models or a [JSON](https://www.json.org/json-en.html) string and the model will respond as JSON or an [Enum](https://docs.python.org/3/library/enum.html) depending on the value set in `response_mime_type`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OjSgf2cDN_bG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Chocolate Chip Cookies\",\n",
      "  \"description\": \"Classic and beloved cookies with chocolate chips.\",\n",
      "  \"ingredients\": [\"All-purpose flour\", \"Baking soda\", \"Salt\", \"Unsalted butter\", \"Granulated sugar\", \"Brown sugar\", \"Eggs\", \"Vanilla extract\", \"Chocolate chips\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    ingredients: list[str]\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"List a few popular cookie recipes and their ingredients.\",\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=Recipe,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKai5CP_PGQF"
   },
   "source": [
    "You can either parse the response string as JSON, or use the `parsed` field to get the response as an object or dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZeyDWbnxO-on",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Chocolate Chip Cookies' description='Classic and beloved cookies with chocolate chips.' ingredients=['All-purpose flour', 'Baking soda', 'Salt', 'Unsalted butter', 'Granulated sugar', 'Brown sugar', 'Eggs', 'Vanilla extract', 'Chocolate chips']\n"
     ]
    }
   ],
   "source": [
    "parsed_response: Recipe = response.parsed\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUSLPrvlvXOc"
   },
   "source": [
    "You also can define a response schema in a Python dictionary. You can only use the supported fields as listed below. All other fields are ignored.\n",
    "\n",
    "- `enum`\n",
    "- `items`\n",
    "- `maxItems`\n",
    "- `nullable`\n",
    "- `properties`\n",
    "- `required`\n",
    "\n",
    "In this example, you instruct the model to analyze product review data, extract key entities, perform sentiment classification (multiple choices), provide additional explanation, and output the results in JSON format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "F7duWOq3vMmS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'rating': 4, 'flavor': 'Strawberry Cheesecake', 'sentiment': 'POSITIVE', 'explanation': \"The reviewer expresses strong positive sentiment with phrases like 'Absolutely loved it!' and 'Best ice cream I've ever had.'\"}, {'rating': 1, 'flavor': 'Mango Tango', 'sentiment': 'NEGATIVE', 'explanation': \"The reviewer indicates a negative sentiment. Although they say 'Quite good', the phrase 'a bit too sweet for my taste' suggests that they did not like the flavor. Also the low rating score is a negative signal.\"}]]\n"
     ]
    }
   ],
   "source": [
    "response_schema = {\n",
    "    \"type\": \"ARRAY\",\n",
    "    \"items\": {\n",
    "        \"type\": \"ARRAY\",\n",
    "        \"items\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"rating\": {\"type\": \"INTEGER\"},\n",
    "                \"flavor\": {\"type\": \"STRING\"},\n",
    "                \"sentiment\": {\n",
    "                    \"type\": \"STRING\",\n",
    "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
    "                },\n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "            },\n",
    "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Analyze the following product reviews, output the sentiment classification, and give an explanation.\n",
    "\n",
    "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
    "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=response_schema,\n",
    "    ),\n",
    ")\n",
    "\n",
    "response_dict = response.parsed\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV1dR-QlTKRs"
   },
   "source": [
    "## Count tokens and compute tokens\n",
    "\n",
    "You can use the `count_tokens()` method to calculate the number of input tokens before sending a request to the Gemini API.\n",
    "\n",
    "For more information, refer to [list and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Syx-fwLkV1j-"
   },
   "source": [
    "### Count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UhNElguLRRNK",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens=9 cached_content_token_count=None\n"
     ]
    }
   ],
   "source": [
    "response = client.models.count_tokens(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What's the highest mountain in Africa?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS-AP7AHUQmV"
   },
   "source": [
    "### Compute tokens\n",
    "\n",
    "The `compute_tokens()` method runs a local tokenizer instead of making an API call. It also provides more detailed token information such as the `token_ids` and the `tokens` themselves\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE: This method is only supported in Vertex AI.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Cdhi5AX1TuH0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_info=[TokensInfo(role='user', token_ids=[1841, 235303, 235256, 573, 32514, 2204, 575, 573, 4645, 5255, 235336], tokens=[b'What', b\"'\", b's', b' the', b' longest', b' word', b' in', b' the', b' English', b' language', b'?'])]\n"
     ]
    }
   ],
   "source": [
    "response = client.models.compute_tokens(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What's the longest word in the English language?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BsP0vXOY7hg"
   },
   "source": [
    "## Search as a tool (Grounding)\n",
    "\n",
    "[Grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview) lets you connect real-world data to the Gemini model.\n",
    "\n",
    "By grounding model responses in Google Search results, the model can access information at runtime that goes beyond its training data which can produce more accurate, up-to-date, and relevant responses.\n",
    "\n",
    "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_M_4RRBdO_3"
   },
   "source": [
    "### Google Search\n",
    "\n",
    "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results.\n",
    "\n",
    "[Dynamic Retrieval](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-with-google-search#dynamic-retrieval) lets you set a threshold for when grounding is used for model responses. This is useful when the prompt doesn't require an answer grounded in Google Search and the supported models can provide an answer based on their knowledge without grounding. This helps you manage latency, quality, and cost more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yeR09J3AZT4U",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The next total solar eclipse in the United States will occur on August 23, 2044. However, totality will only be visible in Montana, North Dakota, and South Dakota. A more expansive total solar eclipse will occur on August 12, 2045, and will span from California to Florida.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounding_chunks=[GroundingChunk(retrieved_context=None, web=GroundingChunkWeb(domain='cbsnews.com', title='cbsnews.com', uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEwqPA69I2VcOXg6up5RZQc8O2DUKvHswJsjAnMrRHK1eW2SL8C-j2C0CYS-JE5UBzHFoY3-lJHcrQgFJZTcdOLnomU-rBUjmkxQOdeCq2V7qd4sjtUJKZ3Yq9vMoxwW0Rox4xRd-wyanTJXSRH5yqyehAmmweNQC0Aa1U=')), GroundingChunk(retrieved_context=None, web=GroundingChunkWeb(domain='wikipedia.org', title='wikipedia.org', uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEUsGIK2RexiNEU47P03YBDtpgNmYcP4vACKlWGNyfaOyiOoKVqQqyB2fY1VIRW9uit4dBG-5yo-CxYHjjSNUFtksxjGwUuzR6D39rN7HL5RLX1oO5JkxsedzdVThLbtZzrTk5RSQ-b9eQXBShxbAlAAOTMCqVDXg==')), GroundingChunk(retrieved_context=None, web=GroundingChunkWeb(domain='wikipedia.org', title='wikipedia.org', uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEzu5TkJjY4xfDVnhwTk3A_o3vgsuMPY90wfo9G8w1qs942iSh5fVd6u4bButL7XhueQ4AbvhqFUhAUqJYyaGNbM4vaaOdkZoPVBFzICj9JtzDl2GT0svDHNw5TE_39Nv-qU0OSdmE_ymb4ZbUZV1p_yg3Cdw9vyQrheARuTM5KiXwdDidKzcuewwvfk8sb')), GroundingChunk(retrieved_context=None, web=GroundingChunkWeb(domain='nasa.gov', title='nasa.gov', uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFdtWyHaUFl-t6UA62cqku05AJEEdyMVp7lhZJ_RQaScvpiDPstjOpa4q6bUyo3GdI9tR6nOi_z-XLE6ThpL8Yh6TYfIyHo5wZbNUXb6qR1NCGeMbDmrafLaoiDOjc6b243_52XesPkIyIZ-aINbLx4Od9_9LGHuC3caA=='))] grounding_supports=[GroundingSupport(confidence_scores=[0.9399393, 0.94119865, 0.6019257, 0.9617482], grounding_chunk_indices=[0, 1, 2, 3], segment=Segment(end_index=80, part_index=None, start_index=None, text='The next total solar eclipse in the United States will occur on August 23, 2044.')), GroundingSupport(confidence_scores=[0.6199697], grounding_chunk_indices=[2], segment=Segment(end_index=163, part_index=None, start_index=81, text='However, totality will only be visible in Montana, North Dakota, and South Dakota.')), GroundingSupport(confidence_scores=[0.64564586, 0.8577316], grounding_chunk_indices=[2, 0], segment=Segment(end_index=273, part_index=None, start_index=164, text='A more expansive total solar eclipse will occur on August 12, 2045, and will span from California to Florida.'))] retrieval_metadata=RetrievalMetadata(google_search_dynamic_retrieval_score=None) retrieval_queries=None search_entry_point=SearchEntryPoint(rendered_content='<style>\\n.container {\\n  align-items: center;\\n  border-radius: 8px;\\n  display: flex;\\n  font-family: Google Sans, Roboto, sans-serif;\\n  font-size: 14px;\\n  line-height: 20px;\\n  padding: 8px 12px;\\n}\\n.chip {\\n  display: inline-block;\\n  border: solid 1px;\\n  border-radius: 16px;\\n  min-width: 14px;\\n  padding: 5px 16px;\\n  text-align: center;\\n  user-select: none;\\n  margin: 0 8px;\\n  -webkit-tap-highlight-color: transparent;\\n}\\n.carousel {\\n  overflow: auto;\\n  scrollbar-width: none;\\n  white-space: nowrap;\\n  margin-right: -12px;\\n}\\n.headline {\\n  display: flex;\\n  margin-right: 4px;\\n}\\n.gradient-container {\\n  position: relative;\\n}\\n.gradient {\\n  position: absolute;\\n  transform: translate(3px, -9px);\\n  height: 36px;\\n  width: 9px;\\n}\\n@media (prefers-color-scheme: light) {\\n  .container {\\n    background-color: #fafafa;\\n    box-shadow: 0 0 0 1px #0000000f;\\n  }\\n  .headline-label {\\n    color: #1f1f1f;\\n  }\\n  .chip {\\n    background-color: #ffffff;\\n    border-color: #d2d2d2;\\n    color: #5e5e5e;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:focus {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:active {\\n    background-color: #d8d8d8;\\n    border-color: #b6b6b6;\\n  }\\n  .logo-dark {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\\n  }\\n}\\n@media (prefers-color-scheme: dark) {\\n  .container {\\n    background-color: #1f1f1f;\\n    box-shadow: 0 0 0 1px #ffffff26;\\n  }\\n  .headline-label {\\n    color: #fff;\\n  }\\n  .chip {\\n    background-color: #2c2c2c;\\n    border-color: #3c4043;\\n    color: #fff;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #353536;\\n  }\\n  .chip:focus {\\n    background-color: #353536;\\n  }\\n  .chip:active {\\n    background-color: #464849;\\n    border-color: #53575b;\\n  }\\n  .logo-light {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\\n  }\\n}\\n</style>\\n<div class=\"container\">\\n  <div class=\"headline\">\\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\\n  </div>\\n  <div class=\"carousel\">\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEiQ_VpmrwEPQ4HLLxWeruNm-efWk2vC5kJfBCJFgT6ZYPpnexiJVepfYpY0Lrowxxd-noKQ3H_1-Jr_9ApuO4wyoUR-yF-6H7m68ecBl0xBgE8qzhspVAACgIJKOpIROIK2wm8V3DT_5ZjIs5lcYz5m08hXn4sIEg76qwpGtZjc7pHMvCjFF_haISWoQQlxzaOF25u8SoIKUL0dx_npvkeLF2gLwdMUEFh8XYn\">next total solar eclipse in United States</a>\\n  </div>\\n</div>\\n', sdk_blob=None) web_search_queries=['next total solar eclipse in United States']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEiQ_VpmrwEPQ4HLLxWeruNm-efWk2vC5kJfBCJFgT6ZYPpnexiJVepfYpY0Lrowxxd-noKQ3H_1-Jr_9ApuO4wyoUR-yF-6H7m68ecBl0xBgE8qzhspVAACgIJKOpIROIK2wm8V3DT_5ZjIs5lcYz5m08hXn4sIEg76qwpGtZjc7pHMvCjFF_haISWoQQlxzaOF25u8SoIKUL0dx_npvkeLF2gLwdMUEFh8XYn\">next total solar eclipse in United States</a>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_search_tool = Tool(google_search=GoogleSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"When is the next total solar eclipse in the United States?\",\n",
    "    config=GenerateContentConfig(tools=[google_search_tool]),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))\n",
    "\n",
    "print(response.candidates[0].grounding_metadata)\n",
    "\n",
    "HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE: For the purposes of this lab, you will skip the following Vertex AI Search section as you do not have a data store to ground your model.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYKAzG1sH-K1"
   },
   "source": [
    "### Vertex AI Search\n",
    "\n",
    "You can use a [Vertex AI Search data store](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es) to connect Gemini to your own custom data.\n",
    "\n",
    "Follow the [get started guide for Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0pb-Kh1xEHU"
   },
   "source": [
    "## Function calling\n",
    "\n",
    "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) in Gemini lets developers create a description of a function in their code, then pass that description to a language model in a request.\n",
    "\n",
    "You can submit a Python function for automatic function calling, which will run the function and return the output in natural language generated by Gemini.\n",
    "\n",
    "You can also submit an [OpenAPI Specification](https://www.openapis.org/) which will respond with the name of a function that matches the description and the arguments to call it with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSUWWlrrlR-D"
   },
   "source": [
    "### Python Function (Automatic Function Calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aRR8HZhLlR-E",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It's hot in Austin, TX.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Example method. Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "        location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    weather_map: dict[str, str] = {\n",
    "        \"Boston, MA\": \"snowing\",\n",
    "        \"San Francisco, CA\": \"foggy\",\n",
    "        \"Seattle, WA\": \"raining\",\n",
    "        \"Austin, TX\": \"hot\",\n",
    "        \"Chicago, IL\": \"windy\",\n",
    "    }\n",
    "    return weather_map.get(location, \"unknown\")\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What is the weather like in Austin?\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[get_current_weather],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4syyLEClGcn"
   },
   "source": [
    "### OpenAPI Specification (Manual Function Calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2BDQPwgcxRN3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=None args={'destination': 'Paris'} name='get_destination'\n"
     ]
    }
   ],
   "source": [
    "get_destination = FunctionDeclaration(\n",
    "    name=\"get_destination\",\n",
    "    description=\"Get the destination that the user wants to go to\",\n",
    "    parameters={\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"destination\": {\n",
    "                \"type\": \"STRING\",\n",
    "                \"description\": \"Destination that the user wants to go to\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "destination_tool = Tool(\n",
    "    function_declarations=[get_destination],\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"I'd like to travel to Paris.\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[destination_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.function_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhDs2X3o0neK"
   },
   "source": [
    "## Code Execution\n",
    "\n",
    "The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output. You can use this code execution capability to build applications that benefit from code-based reasoning and that produce text output. For example, you could use code execution in an application that solves equations or processes text.\n",
    "\n",
    "The Gemini API provides code execution as a tool, similar to function calling.\n",
    "After you add code execution as a tool, the model decides when to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1W-3c7sy0nyz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: Language.PYTHON\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "```\n",
       "def fibonacci(n):\n",
       "    if n <= 0:\n",
       "        return 0\n",
       "    elif n == 1:\n",
       "        return 1\n",
       "    else:\n",
       "        a, b = 0, 1\n",
       "        for _ in range(2, n + 1):\n",
       "            a, b = b, a + b\n",
       "        return b\n",
       "\n",
       "fib_20 = fibonacci(20)\n",
       "print(f'{fib_20=}')\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcome: Outcome.OUTCOME_OK\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "`fib_20=6765\n",
       "`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[code_execution_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.executable_code:\n",
    "        print(\"Language:\", part.executable_code.language)\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"\"\"\n",
    "```\n",
    "{part.executable_code.code}\n",
    "```\n",
    "\"\"\"\n",
    "            )\n",
    "        )\n",
    "    if part.code_execution_result:\n",
    "        print(\"\\nOutcome:\", part.code_execution_result.outcome)\n",
    "        display(Markdown(f\"`{part.code_execution_result.output}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d2d8fdf1d12"
   },
   "source": [
    "## Spatial Understanding\n",
    "\n",
    "Gemini 2.0 includes improved spatial understanding and object detection capabilities. Check out this notebook for examples:\n",
    "\n",
    "- [2D spatial understanding with Gemini 2.0](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/spatial-understanding/spatial_understanding.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQwiONFdVHw5"
   },
   "source": [
    "## What's next\n",
    "\n",
    "- See the [Google Gen AI SDK reference docs](https://googleapis.github.io/python-genai/).\n",
    "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
    "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro_gemini_2_0_flash.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
